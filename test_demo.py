#!/usr/bin/env python3
"""
Demo script to test PDF extraction without requiring the large model.
"""

from pathlib import Path
from peer_reviewer.pdf_processor import extract_text_from_pdf, get_pdf_metadata

def main():
    """Test the PDF processing functionality."""
    
    # Test with the sample paper
    paper_path = Path("papers/AI Agents vs. Agentic AI.pdf")
    
    if not paper_path.exists():
        print(f"Error: Paper file not found at {paper_path}")
        return
    
    print("=== PDF Extraction Demo ===")
    print(f"Processing: {paper_path.name}")
    
    # Extract metadata
    print("\n1. Extracting metadata...")
    metadata = get_pdf_metadata(paper_path)
    for key, value in metadata.items():
        print(f"   {key}: {value}")
    
    # Extract text content
    print("\n2. Extracting text content...")
    text_content = extract_text_from_pdf(paper_path)
    
    print(f"   ✅ Extracted {len(text_content)} characters")
    print(f"   Text preview (first 500 chars):")
    print(f"   {text_content[:500]}...")
    
    # Count pages by looking for page markers
    pages = text_content.count("--- Page")
    print(f"   Estimated pages: {pages + 1}")
    
    # Create a mock LaTeX review (what the AI model would generate)
    print("\n3. Mock LaTeX generation...")
    mock_latex = create_mock_latex_review(text_content[:1000])  # Use first 1000 chars
    
    print(f"   Generated {len(mock_latex)} character LaTeX document")
    
    # Save to reviews directory
    reviews_dir = Path("reviews")
    reviews_dir.mkdir(exist_ok=True)
    
    output_file = reviews_dir / f"{paper_path.stem}_demo_review.tex"
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write(mock_latex)
    
    print(f"   ✅ Saved to: {output_file}")
    print(f"\n=== Demo completed successfully! ===")

def create_mock_latex_review(paper_excerpt: str) -> str:
    """Create a mock LaTeX review to demonstrate the expected output format."""
    
    return f"""\\documentclass[12pt,letterpaper]{{article}}
\\usepackage[utf8]{{inputenc}}
\\usepackage[T1]{{fontenc}}
\\usepackage{{amsmath,amsfonts,amssymb}}
\\usepackage{{geometry}}
\\usepackage{{fancyhdr}}
\\usepackage{{titlesec}}
\\usepackage{{natbib}}

\\geometry{{margin=1in}}
\\pagestyle{{fancy}}
\\fancyhf{{}}
\\rhead{{Peer Review}}
\\lhead{{Generated by gpt-oss-20b}}
\\cfoot{{\\thepage}}

\\title{{Peer Review: AI Agents vs. Agentic AI Analysis}}
\\author{{AI-Generated Review\\\\Generated by gpt-oss-20b Model}}
\\date{{\\today}}

\\begin{{document}}

\\maketitle

\\section{{Executive Summary}}

This paper presents a comprehensive analysis distinguishing between AI Agents and Agentic AI concepts. The work provides valuable conceptual clarity in an increasingly complex field where terminology often overlaps and creates confusion among researchers and practitioners.

\\textbf{{Paper Excerpt Analyzed:}}
\\begin{{quote}}
\\textit{{{paper_excerpt[:200]}...}}
\\end{{quote}}

\\section{{Strengths and Contributions}}

\\begin{{enumerate}}
    \\item \\textbf{{Conceptual Clarity}}: The paper addresses an important terminological confusion in the AI field
    \\item \\textbf{{Structured Approach}}: Well-organized taxonomy and classification system
    \\item \\textbf{{Comprehensive Coverage}}: Broad scope covering applications and challenges
    \\item \\textbf{{Practical Relevance}}: Addresses real-world implementation concerns
\\end{{enumerate}}

\\section{{Weaknesses and Areas for Improvement}}

\\begin{{enumerate}}
    \\item \\textbf{{Empirical Validation}}: Limited experimental validation of proposed concepts
    \\item \\textbf{{Implementation Details}}: Could benefit from more concrete implementation examples
    \\item \\textbf{{Comparative Analysis}}: More direct comparison with existing frameworks needed
\\end{{enumerate}}

\\section{{Detailed Technical Comments}}

\\subsection{{Methodology}}
The taxonomical approach is sound, though it would benefit from:
\\begin{{itemize}}
    \\item More rigorous validation criteria
    \\item Cross-validation with industry practitioners
    \\item Integration with existing AI architecture patterns
\\end{{itemize}}

\\subsection{{Contributions to Field}}
This work fills an important gap in AI terminology standardization. The distinction between autonomous agents and agentic AI systems is valuable for:
\\begin{{itemize}}
    \\item Academic research clarity
    \\item Industry implementation guidance  
    \\item Educational framework development
\\end{{itemize}}

\\section{{Minor Issues}}

\\begin{{itemize}}
    \\item Some figures could be larger for better readability
    \\item Bibliography formatting could be more consistent
    \\item Abstract could be more concise while maintaining key points
\\end{{itemize}}

\\section{{Overall Recommendation}}

\\textbf{{Recommendation: Accept with Minor Revisions}}

This paper makes a valuable contribution to AI terminology and conceptual frameworks. The work is technically sound and addresses an important need in the field. With minor revisions addressing the implementation details and empirical validation concerns, this would be a strong addition to the literature.

\\textbf{{Confidence Level: High}} - The reviewer has significant expertise in AI systems and agent architectures.

\\section{{Conclusion}}

This review was generated using the gpt-oss-20b model as a demonstration of automated peer review capabilities. The analysis is based on the provided paper content and follows standard academic peer review conventions.

\\textbf{{Note:}} This is a demonstration review generated by an AI system. Actual peer reviews should always involve human expert evaluation.

\\end{{document}}"""

if __name__ == "__main__":
    main()